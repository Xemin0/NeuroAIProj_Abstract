{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fFyfJ27WTq38"
   },
   "source": [
    "It has been observed in prior work that tasks sharing some underlying structure will exhibit overlapping neural activity. For instance, Yang et. al. (2019) trained RNNs on several cognitive tasks and observed clustering in the neural activity space: some clusters specialized to particular tasks, while others were shared between tasks. In theory, it is also possible to observe a completely distributed representation (i.e. no modular clusters). While Yang focused on sensory tasks, we aim to study tasks involving abstract relations: transitive inference and divisibility. These tasks are likely to have some common underlying structure, as both represent transitive relations. We will compare the neural geometry of the same RNN trained on one of these tasks at a time to that trained on both (using interleaving).\n",
    "\n",
    "Questions we hope to answer: How will the neural representation of a given task change when more than one task is learned simultaneously? In the latter case, will we find that the activations shared between the two tasks are also present in some form when only one task is learned at a time? That isâ€”does a neural network organize its activity differently when related tasks must be learned together? We will use RDM analysis and dimensionality reduction techniques to look for specialized clusters in neural activity space. We will then compare our networks using RSA/RDA, as well as dynamics-based methods such as DSA and fixed/slow point analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "id": "QAxgYljN5Txw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10abbbad0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# General\n",
    "import numpy as np\n",
    "#import pandas as pd\n",
    "#from scipy.stats import zscore\n",
    "import random\n",
    "#from statistics import mean\n",
    "\n",
    "# Deep learning\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# # Response visualizations\n",
    "# !pip install umap-learn\n",
    "# import umap\n",
    "#import matplotlib as mpl\n",
    "#from matplotlib import pyplot as plt\n",
    "#import seaborn as sns\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(12)\n",
    "torch.manual_seed(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Tasks Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vz3tYw747mMA"
   },
   "outputs": [],
   "source": [
    "# Transitive Inference: (i.e. index 0 is greater than index 1 = \"A > B\")\n",
    "# Example stimulus: [[1, 0, 0],[0, 1, 0]]\n",
    "# Example output: 0\n",
    "\n",
    "# Subset Inclusion: (i.e. index 0 is greater than index 1 = \"A \\contains B\")\n",
    "# Example stimulus: [[1, 1, 1],[0, 1, 0]]\n",
    "# Example output: 0 = \"A \\contains B\"\n",
    "\n",
    "# Divisibility:\n",
    "# Example stimulus: [6,3]\n",
    "# Example output: 0 = \"A is divisble by B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "72VbeOoYExHC",
    "outputId": "6072a5d3-b2c6-4696-d213-fd476d400bbc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,0,0] < [1,0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Task Design and Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "93onUzVT5a-f"
   },
   "outputs": [],
   "source": [
    "# @title Task design\n",
    "def int2bits(n, width):\n",
    "    '''\n",
    "    Convert an Integer to Its Binary Representation as a List/Array/Tensor\n",
    "    e.g. n = 3, width = 4 -> [0, 0, 1, 1]\n",
    "    '''\n",
    "    return [int(b) for b in bin(n)[2:].zfill(width)] # bin() returns a str with prefix '0b'\n",
    "    \n",
    "\n",
    "\n",
    "def gen_batch(batch_size, n_elements = 3, \n",
    "              task = 'ti'):\n",
    "    '''\n",
    "    Generate a Batch of Stimuli (list) for the Desired Task\n",
    "    \n",
    "    Inputs:\n",
    "    - batch_size   : (int) num of stimulus\n",
    "    - n_elements   : (int) Total number of elements on the base set\n",
    "    - task         : (str)\n",
    "                     'ti' - Transitive Inference; without Reflexitivity (relation with itself)\n",
    "                     'si' - Subset Inclusion; \n",
    "                     'div'- Divisibility; without 0\n",
    "\n",
    "    Returns: [[A, B], label] x batch_size       ## of shape [batch_size, 2, n_elements]\n",
    "    '''\n",
    "    assert task in ['ti',\n",
    "                    'si',\n",
    "                    'div'], f'Requested Task [{task}] Not Supported!'\n",
    "    stimuli = []\n",
    "    if 'ti' == task.lower() or 'div' == task.lower():\n",
    "        max_b_size = int(n_elements)\n",
    "        # Transitive Inference\n",
    "        if 'ti' == task.lower():\n",
    "            # All possible instances\n",
    "            stimulus_dict = np.eye(n_elements, dtype = int)\n",
    "            np.random.shuffle(stimulus_dict)\n",
    "            # Randomly sample two instances in the dict as a stimulus\n",
    "            for pair_id in range(batch_size):\n",
    "                dict_indices = random.sample(range(max_b_size), k = 2) # without replacement\n",
    "                # target = which instance is greater\n",
    "                target = 0 if dict_indices[0] > dict_indices[1] else 1\n",
    "                stimuli.append([stimulus_dict[dict_indices].tolist(), target])\n",
    "        else: # Divisibility\n",
    "            for pair_id in range(batch_size):\n",
    "                stimulus_dict = random.sample(range(1, max_b_size + 1), k = 2) # excluding 0\n",
    "                # target = if the previous is divisible by the latter\n",
    "                target = int(0 == stimulus_dict[0] % stimulus_dict[1])\n",
    "                stimuli.append([stimulus_dict, target])\n",
    "    # Subset Inclusion\n",
    "    elif 'si' == task.lower():\n",
    "        max_b_size = 2 ** int(n_elements)\n",
    "        # randomly sample two instances\n",
    "        for pair_id in range(batch_size):\n",
    "            idx_A, idx_B = random.sample(range(max_b_size), k = 2)\n",
    "            # target if the previous is a superset of the latter\n",
    "            A, B = np.array(int2bits(idx_A, width = n_elements)), np.array(int2bits(idx_B, n_elements))\n",
    "            element_indices_B = np.arange(n_elements)[1 == B]\n",
    "            target = int(A[element_indices_B].all()) # if non-zero entries in B are also in A\n",
    "            stimuli.append([[A.tolist(), B.tolist()], target])\n",
    "    return stimuli\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[[1, 0, 1, 0], [0, 0, 1, 1]], 0],\n",
       " [[[0, 0, 1, 0], [1, 1, 1, 1]], 0],\n",
       " [[[0, 1, 1, 0], [0, 1, 0, 0]], 1],\n",
       " [[[1, 1, 0, 1], [0, 0, 1, 1]], 0],\n",
       " [[[1, 1, 0, 1], [0, 0, 0, 1]], 1],\n",
       " [[[1, 0, 0, 1], [0, 0, 0, 0]], 1],\n",
       " [[[1, 1, 0, 1], [1, 1, 1, 0]], 0],\n",
       " [[[0, 1, 1, 0], [1, 1, 1, 0]], 0],\n",
       " [[[0, 0, 0, 1], [0, 0, 1, 0]], 0],\n",
       " [[[1, 0, 0, 0], [0, 1, 1, 1]], 0],\n",
       " [[[0, 0, 1, 0], [1, 1, 1, 0]], 0],\n",
       " [[[1, 0, 1, 1], [1, 0, 1, 0]], 1]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vdata = gen_batch(12, 4, task = 'si')\n",
    "vdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 2, 4])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZpJyPaV3Fu3E",
    "outputId": "704bcf5a-a4cb-4a43-8c5a-8acae6b6424e"
   },
   "source": [
    "### Data Preparation (PyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbstractTaskDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.raw_data = data\n",
    "        #self.data, self.labels = torch.tensor([d for d,_ in data]), torch.tensor([l for _,l in data])\n",
    "        self.data, self.labels = [d for d,_ in data],[l for _,l in data]\n",
    "    def __getitem__(self, idx):\n",
    "        #return torch.tensor(self.raw_data[idx][0]), torch.tensor(self.raw_data[idx][1])\n",
    "        return torch.tensor(self.data[idx], dtype = torch.float), torch.tensor(self.labels[idx], dtype = torch.float)\n",
    "    def __len__(self):\n",
    "        return len(self.raw_data)\n",
    "    \n",
    "### Data Loader, Train_Test split and Shuffle Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "si_datast = AbstractTaskDataset(vdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(si_datast, batch_size = 4, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 0., 1., 0.],\n",
       "         [0., 0., 1., 1.]],\n",
       "\n",
       "        [[0., 0., 1., 0.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[0., 1., 1., 0.],\n",
       "         [0., 1., 0., 0.]],\n",
       "\n",
       "        [[1., 1., 0., 1.],\n",
       "         [0., 0., 1., 1.]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d, l = next(iter(train_loader))\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = si_datast[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Backbones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. MLP\n",
    "class MLP(nn.Module):\n",
    "    '''\n",
    "    MLP with Leaky ReLU as Intermediate Activations\n",
    "    input_dim  :\n",
    "    hidden_dim :\n",
    "    output_dim :\n",
    "    num_layers :\n",
    "    dp_rate    : dropout rate\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, \n",
    "                 num_layers = 2, dp_rate = 0.1):\n",
    "        super(MLP, self).__init__()\n",
    "        # Hyperparameters\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        c_in, c_out = input_dim, hidden_dim\n",
    "        layers = []\n",
    "        for lid in range(num_layers - 1):\n",
    "            layers += [nn.Linear(c_in, c_out),\n",
    "                       nn.LeakyReLU(inplace = True),\n",
    "                       nn.Dropout(dp_rate)]\n",
    "            c_in = hidden_dim\n",
    "        layers += [nn.Linear(c_in, output_dim)]\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "# 2. Simple RNN\n",
    "class SimpleRNN(nn.Module):\n",
    "    '''\n",
    "    RNN in its Simplest Form using nn.RNN\n",
    "    Activation Choices: 'relu' or 'tanh'\n",
    "\n",
    "        - input_dim  : input feat dim\n",
    "        - hidden_dim : \n",
    "        - output_dim : \n",
    "        - num_layers : number of RNN units\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim = None, \n",
    "                 num_layers = 1, activation = 'relu'):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        # Hyperparams\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, num_layers,\n",
    "                          batch_first = True, nonlinearity = activation)\n",
    "        self.readout = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, h = None):\n",
    "        '''\n",
    "        Shape\n",
    "        Inputs:\n",
    "            - x      : [batch_size, seq_len, input_dim]\n",
    "            - h      : [num_layers, batch_size, hidden_dim]\n",
    "        ----\n",
    "        Intermediate:\n",
    "            - out    : [batch_size, seq_len, hidden_dim]\n",
    "            - hidden : [num_layers, batch_size, hidden_dim]\n",
    "        ----\n",
    "        Outputs:\n",
    "            - output : [batch_size, output_dim]\n",
    "            - hidden : [num_layers, batch_size, hidden_dim]\n",
    "        '''\n",
    "        out, hidden = self.rnn(x, h)\n",
    "        # Return pred of each seq in the batch\n",
    "        output = self.readout(out[:, -1,:]) \n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Hybrid Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    '''\n",
    "    A Higher Level Model for Three Tasks that Administrates \n",
    "      - Trunnk Part to Generate Common Hidden Representations\n",
    "      - Multiple Downstreaming Readout Heads\n",
    "\n",
    "      ##### Trunk Net's output dimension needs to be an even number for RNN to work\n",
    "      ##### Requires Handling of Hidden States for RNN \n",
    "      #####\n",
    "    '''\n",
    "    def __init__(self, trunk_net, hidden_dim, output_dim = 1,\n",
    "                num_layers = 2, seq_len = 2):\n",
    "        '''\n",
    "        seq_len : the number of items in the flattened input seq\n",
    "        '''\n",
    "        super(MyModel, self).__init__()\n",
    "        # Parameters\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        self.trunk = trunk_net\n",
    "        if trunk_net.output_dim % seq_len:\n",
    "            print(f\"The output dim of 'trunk_net' is better to be divisible by the length of an input sequence!!\\nCurrent trunk_net.output_dim = {self.trunk_net.output_dim} and seq_len = {self.seq_len}\")\n",
    "            \n",
    "        self.head_mlp = MLP(trunk_net.output_dim, hidden_dim, output_dim = output_dim, num_layers = num_layers)\n",
    "        self.head_rnn = SimpleRNN(trunk_net.output_dim // self.seq_len, hidden_dim, output_dim, num_layers = num_layers) ###\n",
    "\n",
    "    def forward(self, x, hidden, task_type = 0):\n",
    "        '''\n",
    "        ### Task Type definition:\n",
    "            - 0 : \n",
    "            - 1 :  other types\n",
    "\n",
    "            - x : [batch_size, sequence_len * feat_dim = 2 * ]\n",
    "            - hidden : [num_layers, batch_size, hidden_dim]\n",
    "        '''\n",
    "        out_trunk = self.trunk(x) # [batch_size, trunk_net.output_dim]\n",
    "        batch_size = x.shape[0]\n",
    "        if 0 == task_type:\n",
    "            # Reshape the RNN's input into [batch_size, seq_len, trunk_net.output_dim / seq_len = -1]\n",
    "            out, hidden = self.head_rnn(out_trunk.reshape((batch_size, self.seq_len, -1)), hidden)\n",
    "        else:\n",
    "            out = self.head_mlp(out_trunk)\n",
    "        return nn.functional.sigmoid(out).squeeze(), hidden \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic Train Method ### Does not handle the devices for now\n",
    "def test(model, dataloader, task_type = 0, loss_func = nn.BCELoss()):\n",
    "    # Eval Mode\n",
    "    model.eval()\n",
    "    hidden = None\n",
    "    total_acc = 0.0\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for x, y_t in dataloader:\n",
    "            b_size = x.shape[0]\n",
    "            # Bemindful of shape changes\n",
    "            y_p = model(x.reshape(b_size, -1), hidden)\n",
    "            '''\n",
    "            # Forward Pass of RNN only\n",
    "            y_p, _ = model(x, hidden)\n",
    "            y_p = F.sigmoid(y_p.squeeze())\n",
    "            '''\n",
    "            # Calculate Loss\n",
    "            loss = loss_func(y_p, y_t).clone().detach()\n",
    "            # Calculate Acc\n",
    "            preds = y_p > 0.5\n",
    "            acc = (preds == y_t).sum().item() / len(y_t)\n",
    "\n",
    "            # Record statistics\n",
    "            total_loss += loss\n",
    "            total_acc += acc\n",
    "    # Back to Train Mode\n",
    "    model.train()\n",
    "    return total_loss / len(dataloader), total_acc / len(dataloader)\n",
    "\n",
    "\n",
    "def train(model, train_dataloader, test_dataloader = None, n_epochs = 20, \n",
    "          tasktype = 0, lr = 0.01,\n",
    "          loss_func = nn.BCELoss()):\n",
    "    loss_lst = []\n",
    "    acc_lst = []\n",
    "    test_acc_lst = []\n",
    "    \n",
    "    # Using Adam by default\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "    model.train()\n",
    "    for e in range(n_epochs + 1):\n",
    "        for x, y_t in train_dataloader:\n",
    "            ## !! Re_init hidden state !!\n",
    "            hidden = None\n",
    "            optimizer.zero_grad() # Clear gradients\n",
    "            # Forward Pass\n",
    "            y_pred, updated_hidden = mymodel(x.reshape(x.shape[0], -1), hidden, tasktype)\n",
    "            loss = loss_func(y_pred, y_t)\n",
    "            \n",
    "            # Backward Pass\n",
    "            loss.backward(retain_graph=True) ### Is the same graph accessed multiple times over different backward pass?\n",
    "            #loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Record Statistics\n",
    "            loss_lst.append(loss.clone().detach())\n",
    "            \n",
    "            preds = y_pred > 0.5\n",
    "            acc = (preds == y_t).sum().item() / len(y_t)\n",
    "            acc_lst.append(acc)\n",
    "            hidden = updated_hidden\n",
    "        if 0 == (e) % 10:\n",
    "            t_loss = 0.0\n",
    "            t_acc = 0.0\n",
    "            if test_dataloader is not None:\n",
    "                t_loss, t_acc = test(model, test_dataloader, task_type, loss_func)\n",
    "            print(f'Epoch [{e}/{n_epochs}]:\\t--LastBatchLoss:{loss:.3f}, TrainAcc:{acc:.3f}, TestLoss:{t_loss:.3f}, TestAcc:{t_acc:.3f}')\n",
    "\n",
    "    return loss_lst, acc_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/20]:\t--LastBatchLoss:0.644, TrainAcc:0.750, TestLoss:0.000, TestAcc:0.000\n",
      "Epoch [10/20]:\t--LastBatchLoss:0.523, TrainAcc:0.750, TestLoss:0.000, TestAcc:0.000\n",
      "Epoch [20/20]:\t--LastBatchLoss:0.028, TrainAcc:1.000, TestLoss:0.000, TestAcc:0.000\n"
     ]
    }
   ],
   "source": [
    "### Example use \n",
    "# Debug\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "input_dim = 4\n",
    "hidden_dim = 8\n",
    "output_dim = 1\n",
    "trunk_net = MLP(input_dim * 2, hidden_dim, hidden_dim)\n",
    "mymodel = MyModel(trunk_net, hidden_dim, output_dim = output_dim)\n",
    "\n",
    "# Train with Task Requiring RNN\n",
    "l_lst, a_lst = train(mymodel, train_loader, tasktype = 0, n_epochs = 20, lr = 0.01)\n",
    "\n",
    "# Train with Task with Linear Readout\n",
    "#history = train(mymodel, train_data, tasktype = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "----\n",
    "### Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Task design\n",
    "def int2bits(n, width):\n",
    "    '''\n",
    "    Convert an Integer to Its Binary Representation as a List/Array/Tensor\n",
    "    e.g. n = 3, width = 4 -> [0, 0, 1, 1]\n",
    "    '''\n",
    "    return [int(b) for b in bin(n)[2:].zfill(width)] # bin() returns a str with prefix '0b'\n",
    "    \n",
    "\n",
    "\n",
    "def gen_batch(batch_size, n_elements = 3, \n",
    "              task = 'ti'):\n",
    "    '''\n",
    "    Generate a Batch of Stimuli (list) for the Desired Task\n",
    "    \n",
    "    Inputs:\n",
    "    - batch_size   : (int) num of stimulus\n",
    "    - n_elements   : (int) Total number of elements on the base set\n",
    "    - task         : (str)\n",
    "                     'ti' - Transitive Inference; without Reflexitivity (relation with itself)\n",
    "                     'si' - Subset Inclusion; \n",
    "                     'div'- Divisibility; without 0\n",
    "\n",
    "    Returns: [[A, B], label] x batch_size       ## of shape [batch_size, 2, n_elements]\n",
    "    '''\n",
    "    assert task in ['ti',\n",
    "                    'si',\n",
    "                    'div'], f'Requested Task [{task}] Not Supported!'\n",
    "    stimuli = []\n",
    "    if 'ti' == task.lower() or 'div' == task.lower():\n",
    "        max_b_size = int(n_elements)\n",
    "        # Transitive Inference\n",
    "        if 'ti' == task.lower():\n",
    "            # All possible instances\n",
    "            stimulus_dict = np.eye(n_elements, dtype = int)\n",
    "            np.random.shuffle(stimulus_dict)\n",
    "            # Randomly sample two instances in the dict as a stimulus\n",
    "            for pair_id in range(batch_size):\n",
    "                dict_indices = random.sample(range(max_b_size), k = 2) # without replacement\n",
    "                # target = which instance is greater\n",
    "                target = 0 if dict_indices[0] > dict_indices[1] else 1\n",
    "                stimuli.append([stimulus_dict[dict_indices].tolist(), target])\n",
    "        else: # Divisibility\n",
    "            for pair_id in range(batch_size):\n",
    "                stimulus_dict = random.sample(range(1, max_b_size + 1), k = 2) # excluding 0\n",
    "                # target = if the previous is divisible by the latter\n",
    "                target = int(0 == stimulus_dict[0] % stimulus_dict[1])\n",
    "                stimuli.append([stimulus_dict, target])\n",
    "    # Subset Inclusion\n",
    "    elif 'si' == task.lower():\n",
    "        max_b_size = 2 ** int(n_elements)\n",
    "        # randomly sample two instances\n",
    "        for pair_id in range(batch_size):\n",
    "            idx_A, idx_B = random.sample(range(max_b_size), k = 2)\n",
    "            # target if the previous is a superset of the latter\n",
    "            A, B = np.array(int2bits(idx_A, width = n_elements)), np.array(int2bits(idx_B, n_elements))\n",
    "            element_indices_B = np.arange(n_elements)[1 == B]\n",
    "            target = int(A[element_indices_B].all()) # if non-zero entries in B are also in A\n",
    "            stimuli.append([[A.tolist(), B.tolist()], target])\n",
    "    return stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def get_test_data(n):\n",
    "    \"\"\"Generate test data for relational tasks.\n",
    "    \"\"\"\n",
    "    test_x = np.zeros((n, n, 2*n))\n",
    "    for i, j in itertools.product(range(n), range(n)):\n",
    "        test_x[i,j,i] = 1 \n",
    "        test_x[i,j,n+j] = 1 \n",
    "    test_x = torch.from_numpy(test_x).float()\n",
    "    test_x = test_x/torch.sqrt(torch.tensor(2))\n",
    "    return test_x\n",
    "\n",
    "def get_transitive_data(n):\n",
    "    \"\"\"Generate training data for TI task.\n",
    "    \"\"\"\n",
    "    test_x = get_test_data(n)\n",
    "    x = test_x[tuple(zip(*([(i, i+1) for i in range(n-1)] + [(i+1, i) for i in range(n-1)])))]\n",
    "    y = torch.tensor([1.]*(n-1)+[-1.]*(n-1))\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = get_transitive_data(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7071, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7071, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.7071, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7071, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.7071, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7071,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.7071, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.7071],\n",
       "        [0.0000, 0.7071, 0.0000, 0.0000, 0.0000, 0.7071, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.7071, 0.0000, 0.0000, 0.0000, 0.7071, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.7071, 0.0000, 0.0000, 0.0000, 0.7071, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.7071, 0.0000, 0.0000, 0.0000, 0.7071,\n",
       "         0.0000]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
