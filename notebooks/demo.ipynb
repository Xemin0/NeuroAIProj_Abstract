{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/stephenchen/projects/NeuroAIProj_Abstract\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stephenchen/projects/NeuroAIProj_Abstract/.venv/lib/python3.12/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "from src.utils.data import Item, Task, powerset_generator\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TI Task Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TI task setup\n",
    "\n",
    "n_items = 100     # size of the universe of ranked items\n",
    "item_vals = range(n_items)\n",
    "\n",
    "# standard setup: one-hot for each element in TI\n",
    "item_values = torch.eye(n_items)      \n",
    "\n",
    "all_permutations = permutations(item_vals)\n",
    "standard_ranking = next(all_permutations)   # tuple\n",
    "random_ranking = next(all_permutations)\n",
    "\n",
    "TI_task1 = Task(\"ti-standard\", item_values.tolist(), standard_ranking)\n",
    "T1_items = TI_task1.initialize_itemset()\n",
    "TI_task2 = Task(\"ti-random\", item_values.tolist(), random_ranking)\n",
    "T2_items = TI_task2.initialize_itemset()\n",
    "\n",
    "full_dataset1 = TI_task1.master_dataset(T1_items)\n",
    "full_dataset2 = TI_task2.master_dataset(T2_items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_config = {\n",
    "    \"batch_size\": 32\n",
    "}\n",
    "\n",
    "# TI task1\n",
    "train_dataset1 = Subset(full_dataset1, full_dataset1.train_indices)\n",
    "test_dataset1 = Subset(full_dataset1, full_dataset1.test_indices)\n",
    "train_loader1 = DataLoader(train_dataset1, **loader_config)\n",
    "test_loader1 = DataLoader(test_dataset1, **loader_config)\n",
    "\n",
    "# TI task2\n",
    "train_dataset2 = Subset(full_dataset2, full_dataset2.train_indices)\n",
    "test_dataset2 = Subset(full_dataset2, full_dataset2.test_indices)\n",
    "train_loader2 = DataLoader(train_dataset2, **loader_config)\n",
    "test_loader2 = DataLoader(test_dataset2, **loader_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in train_loader1:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 200])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SI Task Setup (incomplete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerset_gen = powerset_generator(3)\n",
    "item_vals = list(powerset_gen)          # be careful of large sets\n",
    "SI_task = Task(\"si\", item_values)\n",
    "# tree = SI_task.construct_tree()         # trees contain chains\n",
    "# chains = tree.chains()                  # get all sets containing comparable items\n",
    "# full_dset = SI_task.master_dataset(chains)\n",
    "# train_dset = Subset(full_dset, full_dset.train_indices)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
