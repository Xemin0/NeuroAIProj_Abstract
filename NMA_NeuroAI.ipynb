{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "It has been observed in prior work that tasks sharing some underlying structure will exhibit overlapping neural activity. For instance, Yang et. al. (2019) trained RNNs on several cognitive tasks and observed clustering in the neural activity space: some clusters specialized to particular tasks, while others were shared between tasks. In theory, it is also possible to observe a completely distributed representation (i.e. no modular clusters). While Yang focused on sensory tasks, we aim to study tasks involving abstract relations: transitive inference, subset inclusion, and divisibility. These tasks are likely to have some common underlying structure, as both represent transitive relations. We will compare the neural geometry of the same model trained on one of these tasks at a time to that trained on both (using interleaving).\n",
        "\n",
        "Finally, we will train an RNN on a secondary task requiring the representations learned in the transitive inference task. While we have not finalized this task, its purpose is to generate interesting dynamics. One example may be: At each time step, a new item (from the items learned during the TI task) will be presented to the RNN. Its task will be to output the items it has seen so far in the correct order at each time step. Another idea is to show the RNN two inputs at each time step and to morph one of the inputs until the relationship between the inputs is flipped (for example, if the first input is ‘greater’, then ‘shrink’ it until the second input is ‘greater’, where the notion of ‘greater than’ is relative to the task). The RNN’s task would be to return 0 while the original relation holds, and 1 once it no longer holds.\n",
        "\n",
        "Questions we hope to answer: How will the neural representation of a given task change when more than one task is learned simultaneously? In the latter case, will we find that the activations shared between the two tasks are also present in some form when only one task is learned at a time? That is—does a neural network organize its activity differently when related tasks must be learned together? We will use RDM analysis and dimensionality reduction techniques to look for specialized clusters in neural activity space. We will then compare our networks using RSA/RDA, as well as dynamics-based methods such as DSA and fixed/slow point analysis."
      ],
      "metadata": {
        "id": "fFyfJ27WTq38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transitive Inference: (i.e. index 0 is greater than index 1 = \"A > B\")\n",
        "# Example stimulus: [[1, 0, 0],[0, 1, 0]]\n",
        "# Example output: 0\n",
        "\n",
        "# Subset Inclusion: (i.e. index 0 is greater than index 1 = \"A \\contains B\")\n",
        "# Example stimulus: [[1, 1, 1],[0, 1, 0]]\n",
        "# Example output: 0 = \"A \\contains B\"\n",
        "\n",
        "# Divisibility:\n",
        "# Example stimulus: [6,3]\n",
        "# Example output: 0 = \"A is divisble by B\""
      ],
      "metadata": {
        "id": "Vz3tYw747mMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "QAxgYljN5Txw",
        "outputId": "54394678-23cb-44fa-d1c6-76006848ae60"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7978e19f7530>"
            ]
          },
          "metadata": {},
          "execution_count": 215
        }
      ],
      "source": [
        "# @title Imports\n",
        "\n",
        "# General\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import zscore\n",
        "import matplotlib as mpl\n",
        "from matplotlib import pyplot as plt\n",
        "import random\n",
        "from statistics import mean\n",
        "\n",
        "# Deep learning\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "\n",
        "# # Response visualizations\n",
        "# !pip install umap-learn\n",
        "# import umap\n",
        "import seaborn as sns\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(12)\n",
        "torch.manual_seed(12)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Helper Functions\n",
        "\n",
        "\n",
        "def get_hidden_activity(net, stimuli, layer_labels):\n",
        "  \"\"\"Retrieve internal representations of network\n",
        "\n",
        "  Args:\n",
        "    net (nn.Module): deep network\n",
        "    stimuli (torch.Tensor): input to the network\n",
        "    layer_labels (list): list of strings with labels of each layer for which\n",
        "      to return its internal representations\n",
        "\n",
        "  Returns:\n",
        "    dict: internal representations at each layer of the network, in\n",
        "      numpy arrays. The keys of this dict are the strings in layer_labels.\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  hidden_activity = {}\n",
        "\n",
        "  # Attach hooks to each layer of the network to store hidden\n",
        "  # representations in hidden_activity\n",
        "  def hook(module, input, output):\n",
        "    module_label = list(net._modules.keys())[np.argwhere([module == m for m in net._modules.values()])[0, 0]]\n",
        "    if module_label in layer_labels:\n",
        "      hidden_activity[module_label] = output.view(stimuli.shape[0], -1).cpu().detach().numpy()\n",
        "  hooks = [layer.register_forward_hook(hook) for layer in net.children()]\n",
        "\n",
        "  # Run stimuli through the network\n",
        "  pred = net.predict(stimuli)\n",
        "\n",
        "  # Remove the hooks\n",
        "  [h.remove() for h in hooks]\n",
        "\n",
        "  return hidden_activity"
      ],
      "metadata": {
        "cellView": "form",
        "id": "rahBbouaQTvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Task design: Part I\n",
        "\n",
        "def make_stimulus_dict(input_length, task='ti'):\n",
        "    stimulus_order_dict = []\n",
        "\n",
        "    if task == 'ti':\n",
        "      for index in range(input_length):\n",
        "        stimulus_key = [0]*input_length\n",
        "        stimulus_key[index] = 1\n",
        "        stimulus_order_dict.append(stimulus_key)\n",
        "      random.shuffle(stimulus_order_dict)\n",
        "\n",
        "    # elif task == \"si\":\n",
        "    #   for index in range(input_length):\n",
        "    #     stimulus_key = [0]*input_length\n",
        "\n",
        "\n",
        "    return stimulus_order_dict\n",
        "\n",
        "def get_batch(batch_size, task, stimulus_dict=None, input_length=3, mode='train'):\n",
        "\n",
        "  # Helpers\n",
        "  def get_binary_vec(input_length):\n",
        "    return [random.randint(0, 1) for _ in range(input_length)]\n",
        "\n",
        "  def make_stimulus(input_length, task='ti'):\n",
        "    if task == 'ti':\n",
        "      if mode == 'test':\n",
        "        dict_indices = random.sample(range(input_length), 2)\n",
        "      elif mode == 'train':\n",
        "        temp_idx = random.sample(range(input_length-1), 1)\n",
        "        dict_indices = [temp_idx[0], temp_idx[0]+1]\n",
        "        random.shuffle(dict_indices)\n",
        "      stimulus = [stimulus_dict[i] for i in dict_indices]\n",
        "\n",
        "      if dict_indices[0] < dict_indices[1]: # If the first item is greater, it appears earlier in the list\n",
        "        target = 0\n",
        "      else:\n",
        "        target = 1\n",
        "\n",
        "    elif task == 'si':\n",
        "      stimulus = [0,0]\n",
        "      while stimulus[0] == stimulus[1]:\n",
        "        stimulus = [get_binary_vec(input_length), get_binary_vec(input_length)]\n",
        "\n",
        "      if stimulus[0] > stimulus[1]: # If first binary number is greater, it is the superset\n",
        "        target = 0\n",
        "      else:\n",
        "        target = 1\n",
        "\n",
        "    # elif task == \"div\":\n",
        "    #   stimulus = [random.sample(range(0, 100, 2),1)[0], random.sample(range(0, 100, 2),1)[0]]\n",
        "    #   if stimulus[0] % stimulus[1] == 0:\n",
        "    #     target = 0\n",
        "    #   else:\n",
        "    #     target = 1\n",
        "\n",
        "    return stimulus, target\n",
        "\n",
        "  stimuli, labels = [make_stimulus(input_length, task) for _ in range(batch_size)]\n",
        "  stimuli = torch.tensor(stimuli).float().to(device)\n",
        "  labels = torch.tensor(labels).float().to(device)\n",
        "\n",
        "  return stimuli, labels"
      ],
      "metadata": {
        "id": "93onUzVT5a-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_length = 5\n",
        "stimulus_dict = make_stimulus_dict(input_length)\n",
        "print(stimulus_dict,'\\n')\n",
        "get_batch(10, 'ti', stimulus_dict, input_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SuEZFTZR_bC",
        "outputId": "0b4033ab-9099-4153-e14d-43a986a5d9ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0, 0, 0, 0, 1], [0, 0, 0, 1, 0], [1, 0, 0, 0, 0], [0, 0, 1, 0, 0], [0, 1, 0, 0, 0]] \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[([[1, 0, 0, 0, 0], [0, 0, 0, 1, 0]], 1),\n",
              " ([[0, 0, 0, 0, 1], [0, 0, 0, 1, 0]], 0),\n",
              " ([[0, 1, 0, 0, 0], [0, 0, 1, 0, 0]], 1),\n",
              " ([[0, 0, 1, 0, 0], [1, 0, 0, 0, 0]], 1),\n",
              " ([[0, 0, 1, 0, 0], [0, 1, 0, 0, 0]], 0),\n",
              " ([[0, 0, 0, 0, 1], [0, 0, 0, 1, 0]], 0),\n",
              " ([[1, 0, 0, 0, 0], [0, 0, 1, 0, 0]], 0),\n",
              " ([[0, 0, 1, 0, 0], [0, 1, 0, 0, 0]], 0),\n",
              " ([[0, 0, 0, 1, 0], [1, 0, 0, 0, 0]], 0),\n",
              " ([[0, 0, 1, 0, 0], [0, 1, 0, 0, 0]], 0)]"
            ]
          },
          "metadata": {},
          "execution_count": 230
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params_dict = {\n",
        "    'batch_size': 10,\n",
        "    'n_epochs': 2,\n",
        "    'dataset_size': 1000,\n",
        "    'learning_rate': 0.0005,\n",
        "    'momentum': .99,\n",
        "    'task': 'ti',\n",
        "    'input_length': 5\n",
        "}"
      ],
      "metadata": {
        "id": "ln4bdayXG_9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Architecture: Feedforward\n",
        "\n",
        "# Inputs: list of two vectors\n",
        "# Outputs: scalar (0/1)\n",
        "\n",
        "class Feedforward(nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "    super(Feedforward, self).__init__()\n",
        "    self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "    self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.fc1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.relu(x)\n",
        "    return x\n",
        "\n",
        "  def predict(self, x):\n",
        "    with torch.no_grad():\n",
        "      return torch.relu(self.forward(x))\n",
        "\n",
        "def train_loop(net, **params_dict, response_dict=False):\n",
        "\n",
        "  # Initialize response dictionary and inputs\n",
        "  if response_dict:\n",
        "    resp_layer_labels = get_resp_layer_labels(net)\n",
        "    resp_dict = {layer : [] for layer in resp_layer_labels}\n",
        "    stimuli_for_hooks = get_resp_layer_inputs()\n",
        "  else: resp_dict = None\n",
        "\n",
        "  for i in range(n_epochs):\n",
        "        for j in range(dataset_size//batch_size):\n",
        "          stimuli, labels = get_batch(batch_size, task, stimulus_dict, input_length)\n"
      ],
      "metadata": {
        "id": "AtR-00o2v5Wa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Math question:\n",
        "# Figure out the best input size vs batch size"
      ],
      "metadata": {
        "id": "YSDKQfDoFHNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Architecture: RNN\n",
        "\n",
        "# Inputs: list of integers x number of time steps\n",
        "# Outputs: list of integers x number of time steps\n",
        "\n",
        "# OR\n",
        "\n",
        "# Inputs: list of two vectors x number of time steps\n",
        "# Outputs: scalar (0/1) x number of time steps\n",
        "\n"
      ],
      "metadata": {
        "id": "82qHWr1gFb7j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}